{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/08 22:23:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/01/08 22:23:52 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n",
      "25/01/08 22:23:53 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "25/01/08 22:24:06 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark Version :3.5.3\n",
      "PySpark Version :3.5.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>movie</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1112e57f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "spark=SparkSession.builder.master(\"yarn\")\\\n",
    "        .appName(\"movie\")\\\n",
    "        .config(\"spark.driver.extraClassPath\",\"/Users/eduardoalberto/opt/spark-3.5.3/jars/mysql-connector-j-9.1.0.jar\")\\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"7\") \\\n",
    "        .config(\"spark.sql.warehouse.dir\", \"hdfs:/user/bigdata/repository/database/\") \\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "        .config(\"spark.executor.cores\", \"4\") \\\n",
    "        .config(\"spark.dynamicAllocation.minExecutors\", \"1\") \\\n",
    "        .config(\"spark.dynamicAllocation.maxExecutors\", \"5\") \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.sparkContext.setLogLevel(\"OFF\") \n",
    "print('PySpark Version :'+spark.version)\n",
    "print('PySpark Version :'+spark.sparkContext.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
      "|nconst   |primaryName        |birthYear|deathYear|primaryProfession                    |knownForTitles                         |\n",
      "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
      "|nm0000001|Fred Astaire       |1899     |1987     |soundtrack,actor,miscellaneous       |tt0050419,tt0072308,tt0031983,tt0053137|\n",
      "|nm0000002|Lauren Bacall      |1924     |2014     |actress,soundtrack                   |tt0037382,tt0038355,tt0117057,tt0071877|\n",
      "|nm0000003|Brigitte Bardot    |1934     |\\N       |actress,soundtrack,music_department  |tt0056404,tt0057345,tt0049189,tt0054452|\n",
      "|nm0000004|John Belushi       |1949     |1982     |actor,soundtrack,writer              |tt0077975,tt0072562,tt0080455,tt0078723|\n",
      "|nm0000005|Ingmar Bergman     |1918     |2007     |writer,director,actor                |tt0083922,tt0050976,tt0050986,tt0060827|\n",
      "|nm0000006|Ingrid Bergman     |1915     |1982     |actress,soundtrack,producer          |tt0077711,tt0034583,tt0036855,tt0038109|\n",
      "|nm0000007|Humphrey Bogart    |1899     |1957     |actor,soundtrack,producer            |tt0043265,tt0034583,tt0042593,tt0037382|\n",
      "|nm0000008|Marlon Brando      |1924     |2004     |actor,soundtrack,director            |tt0047296,tt0070849,tt0068646,tt0078788|\n",
      "|nm0000009|Richard Burton     |1925     |1984     |actor,soundtrack,producer            |tt0057877,tt0087803,tt0061184,tt0059749|\n",
      "|nm0000010|James Cagney       |1899     |1986     |actor,soundtrack,director            |tt0029870,tt0042041,tt0055256,tt0035575|\n",
      "|nm0000011|Gary Cooper        |1901     |1961     |actor,soundtrack,producer            |tt0034167,tt0044706,tt0027996,tt0035896|\n",
      "|nm0000012|Bette Davis        |1908     |1989     |actress,soundtrack,make_up_department|tt0031210,tt0035140,tt0042192,tt0056687|\n",
      "|nm0000013|Doris Day          |1922     |2019     |soundtrack,actress,producer          |tt0053172,tt0048317,tt0045591,tt0049470|\n",
      "|nm0000014|Olivia de Havilland|1916     |2020     |actress,soundtrack                   |tt0040806,tt0041452,tt0031381,tt0029843|\n",
      "|nm0000015|James Dean         |1931     |1955     |actor,miscellaneous                  |tt0048545,tt0048028,tt0049261,tt0039123|\n",
      "|nm0000016|Georges Delerue    |1925     |1992     |composer,soundtrack,music_department |tt8847712,tt0069946,tt0091763,tt0096320|\n",
      "|nm0000017|Marlene Dietrich   |1901     |1992     |soundtrack,actress,music_department  |tt0055031,tt0021156,tt0051201,tt0052311|\n",
      "|nm0000018|Kirk Douglas       |1916     |2020     |actor,producer,soundtrack            |tt0080736,tt0054331,tt0049456,tt0043338|\n",
      "|nm0000019|Federico Fellini   |1920     |1993     |writer,director,assistant_director   |tt0053779,tt0071129,tt0050783,tt0056801|\n",
      "|nm0000020|Henry Fonda        |1905     |1982     |actor,producer,soundtrack            |tt0051207,tt0050083,tt0082846,tt0032551|\n",
      "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", True).csv('hdfs:/user/bigdata/repository/input/data_2022*.csv')\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.filter(\"primaryProfession in ('soundtrack')\").show()\n",
    "df = (df.filter(\" deathYear <> r'\\\\N' and deathYear <> r'\\\\N'  \")\n",
    "        .withColumn('profession_array',(F.split(F.col(\"primaryProfession\"), \",\")))\n",
    "        .withColumn('knownForTitles_array',(F.split(F.col(\"knownForTitles\"),\",\")))\n",
    "\n",
    "        \n",
    "\n",
    ")\n",
    "dfs = df.select(F.col(\"nconst\"),\n",
    "                F.col(\"primaryName\"),\n",
    "                F.col(\"birthYear\"),\n",
    "                F.col(\"deathYear\"),\n",
    "                F.explode(F.col(\"profession_array\")).alias(\"profession\"),\n",
    "                F.explode(F.col(\"knownForTitles_array\")).alias(\"Titles\"))\n",
    "\n",
    "                \n",
    "dfs.show()\n",
    "\n",
    "#123.627.002\n",
    "#11.845.112\n",
    "#357.801\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession,Row,DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def dp_etl(df: DataFrame) -> DataFrame :\n",
    "\n",
    "    dfs = (df.filter(\" deathYear <> r'\\\\N' and deathYear <> r'\\\\N' \")\n",
    "                .withColumn('profession_array',(F.split(F.col(\"primaryProfession\"), \",\")))\n",
    "                .withColumn('knownForTitles_array',(F.split(F.col(\"knownForTitles\"),\",\")))\n",
    "                .select(F.col(\"nconst\"),\n",
    "                        F.col(\"primaryName\"),\n",
    "                        F.col(\"birthYear\"),\n",
    "                        F.col(\"deathYear\"),\n",
    "                        F.explode(F.col(\"profession_array\")).alias(\"profession\"),\n",
    "                        F.explode(F.col(\"knownForTitles_array\")).alias(\"Titles\"))\n",
    "    )\n",
    "    dffull = (dfs.filter(\"profession <> r'\\\\N' and Titles <> r'\\\\N' \")\n",
    "                 .dropDuplicates([\"profession\",\"Titles\"]))\n",
    "    return dffull\n",
    "\n",
    "\n",
    "df = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", True).csv('hdfs:/user/bigdata/repository/input/data_2022*.csv')\n",
    "tb = dp_etl(df)\n",
    "\n",
    "tb.write.mode('overwrite').partitionBy(\"deathYear\").parquet(\"/user/bigdata/repository/parquet/movie.parquet\")\n",
    "\n",
    "#spark.table(\"dbdev001.tb_movie\").show()\n",
    "#spark.sql(\"drop table if exists movie\")\n",
    "#tb.limit(1500).write.mode('overwrite').partitionBy(\"deathYear\").saveAsTable(\"movie\")\n",
    "# tb.limit(1000).write.mode(\"overwrite\").jdbc(\"jdbc:mysql://localhost:3306/myDbUser\", \"myDbUser.movie\",properties={\"user\": \"root\", \"password\": \"mysql\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "676382"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.sql(\"show partitions movie\").show()\n",
    "# spark.sql(\"desc table extended movie\").show()\n",
    "# spark.table(\"movie\").count()\n",
    "\n",
    "df02 = spark.read.parquet(\"/user/bigdata/repository/parquet/movie.parquet\")\n",
    "df02.count()\n",
    "\n",
    "\n",
    "\n",
    "#3.449.518\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#123.627.027\n",
    "#11.845.112"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
