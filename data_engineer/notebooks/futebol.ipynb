{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/11 23:12:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import json, requests\n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import *\n",
    "import os.path as path\n",
    "\n",
    "spark=SparkSession.builder.master(\"local[1]\")\\\n",
    "    .appName(\"Music\")\\\n",
    "    .config(\"spark.driver.extraClassPath\",\"/Users/eduardoalberto/opt/spark/jars/mssql-jdbc-7.4.1.jre8.jar\" ) \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "\n",
    "# df= spark.read.jdbc(\"jdbc:sqlserver://localhost:1433;databaseName=DBDWP511\", \"tb_camp_brasileiro\",properties={\"user\": \"sa\", \"password\": \"Numsey@Password!\"})\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+---------+---------+--------------+-----------+-----------+-----------+-----------+----------+----------+-------------------+----------+-------+-------+---------+---------+-------------+\n",
      "|    tournament|               home|home_goal|away_goal|          away|home_corner|away_corner|home_attack|away_attack|home_shots|away_shots|               time|      date|ht_diff|at_diff|ht_result|at_result|total_corners|\n",
      "+--------------+-------------------+---------+---------+--------------+-----------+-----------+-----------+-----------+----------+----------+-------------------+----------+-------+-------+---------+---------+-------------+\n",
      "|Copa do Brasil|   Vasco Da Gama RJ|      0.0|      0.0|           ABC|        6.0|        2.0|      133.0|       82.0|       9.0|       6.0|2023-05-11 00:30:00|2023-03-17|    0.0|    0.0|     DRAW|     DRAW|          8.0|\n",
      "|Copa do Brasil|             Gremio|      3.0|      0.0|   Ferroviario|       10.0|        3.0|       98.0|       81.0|      30.0|      11.0|2023-05-11 23:00:00|2023-03-16|    3.0|   -3.0|      WON|     LOST|         13.0|\n",
      "|Copa do Brasil|                CSA|      1.0|      0.0|       Brusque|        4.0|        4.0|      105.0|      136.0|      10.0|      13.0|2023-05-11 22:00:00|2023-03-16|    1.0|   -1.0|      WON|     LOST|          8.0|\n",
      "|Copa do Brasil|        Ypiranga RS|      3.0|      1.0|    Bragantino|        7.0|       11.0|      103.0|      119.0|       7.0|      18.0|2023-05-11 00:30:00|2023-03-16|    2.0|   -2.0|      WON|     LOST|         18.0|\n",
      "|Copa do Brasil|        Botafogo RJ|      7.0|      1.0|   Brasiliense|        8.0|        5.0|      107.0|      121.0|      14.0|      15.0|2023-05-11 23:00:00|2023-03-15|    6.0|   -6.0|      WON|     LOST|         13.0|\n",
      "|Copa do Brasil|                CRB|      5.0|      0.0|   Operario MS|        6.0|        4.0|      130.0|       94.0|      18.0|       5.0|2023-05-11 22:30:00|2023-03-15|    5.0|   -5.0|      WON|     LOST|         10.0|\n",
      "|Copa do Brasil|             Ituano|      1.0|      1.0|         Ceara|        6.0|        4.0|      103.0|       99.0|      14.0|      10.0|2023-05-11 22:00:00|2023-03-15|    0.0|    0.0|     DRAW|     DRAW|         10.0|\n",
      "|Copa do Brasil|    Aguia de Maraba|      0.0|      0.0|         Goias|        1.0|       11.0|       69.0|       95.0|       9.0|      23.0|2023-05-11 22:00:00|2023-03-15|    0.0|    0.0|     DRAW|     DRAW|         12.0|\n",
      "|Copa do Brasil|Atletico Goianiense|      1.0|      1.0| Volta Redonda|        7.0|        4.0|      128.0|       88.0|      14.0|       7.0|2023-05-11 22:00:00|2023-03-15|    0.0|    0.0|     DRAW|     DRAW|         11.0|\n",
      "|Copa do Brasil|        Nova Iguacu|      5.0|      2.0|    Nova Mutum|        6.0|        3.0|      113.0|       77.0|      15.0|       7.0|2023-05-11 18:30:25|2023-03-15|    3.0|   -3.0|      WON|     LOST|          9.0|\n",
      "|Copa do Brasil|           Tombense|      1.0|      0.0|         Retro|        6.0|        6.0|      110.0|      111.0|      14.0|      11.0|2023-05-11 00:30:00|2023-03-09|    1.0|   -1.0|      WON|     LOST|         12.0|\n",
      "|Copa do Brasil|               Remo|      2.0|      1.0|      Sao Luiz|       10.0|        3.0|      122.0|       99.0|      16.0|       7.0|2023-05-11 23:00:00|2023-03-08|    1.0|   -1.0|      WON|     LOST|         13.0|\n",
      "|Copa do Brasil|           Camboriu|      0.0|      1.0|      EC Bahia|        2.0|        6.0|       91.0|      120.0|      11.0|       8.0|2023-05-11 22:00:00|2023-03-08|   -1.0|    1.0|     LOST|      WON|          8.0|\n",
      "|Copa do Brasil|  Brasil de Pelotas|      2.0|      0.0|   Ponte Preta|        4.0|        7.0|       83.0|       94.0|       5.0|      24.0|2023-05-11 23:00:00|2023-03-07|    2.0|   -2.0|      WON|     LOST|         11.0|\n",
      "|Copa do Brasil|            Sergipe|      1.0|      1.0|   Botafogo RJ|        4.0|       10.0|       96.0|      130.0|      10.0|      11.0|2023-05-11 23:00:00|2023-03-02|    0.0|    0.0|     DRAW|     DRAW|         14.0|\n",
      "|Copa do Brasil|            Maringa|      2.0|      1.0|Sampaio Correa|        8.0|        3.0|      169.0|      112.0|      21.0|       6.0|2023-05-11 23:00:00|2023-03-02|    1.0|   -1.0|      WON|     LOST|         11.0|\n",
      "|Copa do Brasil|             Iguatu|      1.0|      0.0|    America RN|        5.0|        0.0|       16.0|       17.0|       2.0|       4.0|2023-05-11 22:15:00|2023-03-02|    1.0|   -1.0|      WON|     LOST|          5.0|\n",
      "|Copa do Brasil|     Real Ariquemes|      0.0|      3.0|      Criciuma|        5.0|        7.0|       99.0|      115.0|       6.0|      12.0|2023-05-11 19:30:00|2023-03-02|   -3.0|    3.0|     LOST|      WON|         12.0|\n",
      "|Copa do Brasil|    Aguia de Maraba|      2.0|      1.0|   Botafogo PB|        5.0|        4.0|       59.0|       44.0|      12.0|       6.0|2023-05-11 19:00:00|2023-03-02|    1.0|   -1.0|      WON|     LOST|          9.0|\n",
      "|Copa do Brasil|           Caldense|      0.0|      3.0|         Ceara|       10.0|        2.0|      106.0|       82.0|      16.0|      13.0|2023-05-11 00:30:00|2023-03-02|   -3.0|    3.0|     LOST|      WON|         12.0|\n",
      "+--------------+-------------------+---------+---------+--------------+-----------+-----------+-----------+-----------+----------+----------+-------------------+----------+-------+-------+---------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pfile = '/Users/eduardoalberto/LoadFile/BR-Football-Dataset.csv'\n",
    "nfile = '/Users/eduardoalberto/LoadFile/BR-Football-DatasetOld.csv'\n",
    "\n",
    "class carga:\n",
    "    def __init__(self,spark):\n",
    "        self.__spark = spark\n",
    "        if path.isfile(pfile):\n",
    "            df = (self.__spark.read\n",
    "                        .format(\"csv\")\n",
    "                        .option(\"delimiter\", \",\")\n",
    "                        .option(\"header\", True)\n",
    "                        .option(\"inferSchema\", True)\n",
    "                        .load(pfile))\n",
    "        else:\n",
    "                df = (self.__spark.read\n",
    "                    .format(\"csv\")\n",
    "                    .option(\"delimiter\", \",\")\n",
    "                    .option(\"header\", True)\n",
    "                    .option(\"inferSchema\", True)\n",
    "                    .load(nfile))\n",
    "        return df.show()\n",
    "df = carga(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validaArq(df):\n",
    "    if path.isfile(pfile):\n",
    "        df = (spark.read\n",
    "            .format(\"csv\")\n",
    "            .option(\"delimiter\", \",\")\n",
    "            .option(\"header\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .load(pfile))\n",
    "    else:\n",
    "        df = (spark.read\n",
    "            .format(\"csv\")\n",
    "            .option(\"delimiter\", \",\")\n",
    "            .option(\"header\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .load(nfile))\n",
    "    return df\n",
    "\n",
    "df = validaArq(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|home_goal|count|\n",
      "+---------+-----+\n",
      "|      8.0|    2|\n",
      "|      0.0| 3648|\n",
      "|      7.0|    7|\n",
      "|      1.0| 5109|\n",
      "|      4.0|  482|\n",
      "|      3.0| 1486|\n",
      "|      2.0| 3381|\n",
      "|      6.0|   35|\n",
      "|      5.0|  124|\n",
      "|      9.0|    2|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(col(\"home_goal\")).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|max(ht_diff)|\n",
      "+------------+\n",
      "|         9.0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max(col(\"ht_diff\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BR-Football-Dataset.csv               dataset_bruto.json\n",
      "BR-Football-DatasetOld.csv            \u001b[1m\u001b[36mgenres\u001b[m\u001b[m/\n",
      "Learning+Compute+Cluster+Policy.json  \u001b[1m\u001b[36mparquet\u001b[m\u001b[m/\n",
      "\u001b[1m\u001b[36marchive\u001b[m\u001b[m/                              \u001b[1m\u001b[36mraw\u001b[m\u001b[m/\n",
      "data.csv\n"
     ]
    }
   ],
   "source": [
    "# %lsmagic\n",
    "# %ldir\n",
    "%ls LoadFile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
