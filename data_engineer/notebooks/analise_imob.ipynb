{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/03 15:00:43 WARN Utils: Your hostname, Eduardos-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.5 instead (on interface en0)\n",
      "22/12/03 15:00:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/12/03 15:00:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pyspark.sql import SparkSession,Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "import os \n",
    "import os.path as path\n",
    "import datetime as dt\n",
    "import sys\n",
    "\n",
    "spark=SparkSession.builder.master(\"local[1]\")\\\n",
    "        .appName(\"Imoveis\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "json = spark.read.json(\"/Users/eduardoalberto/LoadFile/dataset_bruto.json\")\n",
    "spark.sparkContext.setLogLevel(\"OFF\") \n",
    "# json.count() #89083\n",
    "# json.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[andar: bigint, area_total: string, area_util: string, tipo_anuncio: string, tipo_unidade: string, vaga: string, banheiros: string, tipo_uso: string, id: string, quartos: string, suites: string, valor: string, tipo: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tratamentojson(df):\n",
    "    schema =   StructType([\n",
    "                StructField(\"andar\",            LongType(),True),\n",
    "                StructField(\"area_total\",       ArrayType(StringType()),True),\n",
    "                StructField(\"area_util\",        ArrayType(StringType()),True),\n",
    "                StructField(\"tipo_anuncio\",     StringType(),True),\n",
    "                StructField(\"tipo_unidade\",     StringType(),True),\n",
    "                StructField(\"andar02\",          StringType(),True),\n",
    "                StructField(\"vaga\",             ArrayType(StringType()),True),\n",
    "                StructField(\"banheiros\",        ArrayType(StringType()),True),\n",
    "                StructField(\"tipo_uso\",         StringType(),True),\n",
    "                StructField(\"caracteristicas\",  ArrayType(StringType()),True),\n",
    "                StructField(\"endereco\",         ArrayType(StringType()),True),\n",
    "                StructField(\"id\",               StringType(),True),\n",
    "                StructField(\"quartos\",          ArrayType(StringType()),True),\n",
    "                StructField(\"valores\",          ArrayType(StringType()),True),\n",
    "                StructField(\"suites\",           ArrayType(StringType()),True),\n",
    "\n",
    "        ]) \n",
    "\n",
    "    df = df.select(df.anuncio)\n",
    "    df = df.withColumn(\"anuncio\", to_json(f.col(\"anuncio\")))\n",
    "    df = df.withColumn(\"anuncio\", from_json(\"anuncio\", schema)).select(col('anuncio.*'))\n",
    "    df = df.filter((df.tipo_uso == \"Residencial\") & (df.tipo_unidade == \"Apartamento\") & (df.tipo_anuncio == \"Usado\"))\n",
    "    df = df.withColumn(\"quartos\", regexp_replace(regexp_replace(df.quartos,r\"\\[\",\"\"),r\"\\]\",\"\"))\n",
    "    df = df.withColumn(\"suites\", regexp_replace(regexp_replace(df.suites,r\"\\[\",\"\"),r\"\\]\",\"\"))\n",
    "    df = df.withColumn(\"banheiros\", regexp_replace(regexp_replace(df.banheiros,r\"\\[\",\"\"),r\"\\]\",\"\"))\n",
    "    df = df.withColumn(\"vaga\", regexp_replace(regexp_replace(df.vaga,r\"\\[\",\"\"),r\"\\]\",\"\"))\n",
    "    df = df.withColumn(\"area_total\", regexp_replace(regexp_replace(df.area_total,r\"\\[\",\"\"),r\"\\]\",\"\"))\n",
    "    df = df.withColumn(\"area_util\", regexp_replace(regexp_replace(df.area_util,r\"\\[\",\"\"),r\"\\]\",\"\"))\n",
    "    df2 = df.withColumn(\"valores\", regexp_replace(regexp_replace(df.valores,r\"\\[\",\"\"),r\"\\]\",\"\")).select(\"id\",\"valores\")\n",
    "    df2 = df2.select(\"id\",json_tuple(col(\"valores\"),\"valor\",\"tipo\")).toDF(\"id2\" ,\"valor\",\"tipo\")\n",
    "    df3 = df.join(df2, df.id == df2.id2, \"inner\")\\\n",
    "            .where(df2.tipo == \"Venda\")\\\n",
    "            .select( \"andar\"\n",
    "                    ,\"area_total\"\n",
    "                    ,\"area_util\"\n",
    "                    ,\"tipo_anuncio\"\n",
    "                    ,\"tipo_unidade\"\n",
    "                    ,\"vaga\"\n",
    "                    ,\"banheiros\"\n",
    "                    ,\"tipo_uso\"\n",
    "                    # ,\"endereco\"\n",
    "                    ,\"id\"\n",
    "                    ,\"quartos\"\n",
    "                    ,\"suites\"\n",
    "                    ,\"valor\"\n",
    "                    ,\"tipo\" )\n",
    "\n",
    "\n",
    "    df3.write.format(\"csv\").mode(\"overwrite\").options(header=\"true\",sep=\"\\t\").save(path=\"/Users/eduardoalberto/LoadFile/CSV/\")\n",
    "    df3.write.parquet(path=\"/Users/eduardoalberto/LoadFile/parquet\", mode=\"overwrite\")    \n",
    "    # df3.write.csv(\"/Users/eduardoalberto/LoadFile/CSV/teste.csv\").mode(\"overwrite\")\n",
    "    \n",
    "    # df3.printSchema()\n",
    "    return df3\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "tratamentojson(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
